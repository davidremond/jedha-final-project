{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m297.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from fastapi import APIRouter, File, UploadFile\n",
    "from PIL import Image\n",
    "from fastapi.responses import FileResponse\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import io\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347f53535c2748519dee7be9e5db089a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 09:29:00.253241: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.models.sequential.Sequential'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 18 variables whereas the saved optimizer has 33 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "mlops_server_uri = 'https://david-rem-jedha-final-project-mlops.hf.space'\n",
    "#model_path = 'models:/lung_7_classes/2'\n",
    "model_path = \"runs:/73f7af9ab4be4dd1be44b4653bb2bf06/model\"\n",
    "\n",
    "mlflow.set_tracking_uri(mlops_server_uri)\n",
    "keras_model = mlflow.keras.load_model(model_path)\n",
    "\n",
    "# Vérifier si le modèle est bien chargé\n",
    "print(type(keras_model))  # Doit être <class 'keras.engine.functional.Functional'> ou <class 'tensorflow.keras.Model'>\n",
    "\n",
    "# Tester une entrée factice\n",
    "#dummy_input = np.zeros((1, 256, 256, 3))  # Ajustez la taille si nécessaire\n",
    "#keras_model(dummy_input)\n",
    "#output = keras_model.predict(dummy_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pyfunc_model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_190\n",
      "InceptionV3\n",
      "conv2d_191\n",
      "flatten_1\n",
      "dense_1\n",
      "\n",
      "\n",
      "input_layer_2\n",
      "conv2d_96\n",
      "batch_normalization_94\n",
      "activation_94\n",
      "conv2d_97\n",
      "batch_normalization_95\n",
      "activation_95\n",
      "conv2d_98\n",
      "batch_normalization_96\n",
      "activation_96\n",
      "max_pooling2d_4\n",
      "conv2d_99\n",
      "batch_normalization_97\n",
      "activation_97\n",
      "conv2d_100\n",
      "batch_normalization_98\n",
      "activation_98\n",
      "max_pooling2d_5\n",
      "conv2d_104\n",
      "batch_normalization_102\n",
      "activation_102\n",
      "conv2d_102\n",
      "conv2d_105\n",
      "batch_normalization_100\n",
      "batch_normalization_103\n",
      "activation_100\n",
      "activation_103\n",
      "average_pooling2d_9\n",
      "conv2d_101\n",
      "conv2d_103\n",
      "conv2d_106\n",
      "conv2d_107\n",
      "batch_normalization_99\n",
      "batch_normalization_101\n",
      "batch_normalization_104\n",
      "batch_normalization_105\n",
      "activation_99\n",
      "activation_101\n",
      "activation_104\n",
      "activation_105\n",
      "mixed0\n",
      "conv2d_111\n",
      "batch_normalization_109\n",
      "activation_109\n",
      "conv2d_109\n",
      "conv2d_112\n",
      "batch_normalization_107\n",
      "batch_normalization_110\n",
      "activation_107\n",
      "activation_110\n",
      "average_pooling2d_10\n",
      "conv2d_108\n",
      "conv2d_110\n",
      "conv2d_113\n",
      "conv2d_114\n",
      "batch_normalization_106\n",
      "batch_normalization_108\n",
      "batch_normalization_111\n",
      "batch_normalization_112\n",
      "activation_106\n",
      "activation_108\n",
      "activation_111\n",
      "activation_112\n",
      "mixed1\n",
      "conv2d_118\n",
      "batch_normalization_116\n",
      "activation_116\n",
      "conv2d_116\n",
      "conv2d_119\n",
      "batch_normalization_114\n",
      "batch_normalization_117\n",
      "activation_114\n",
      "activation_117\n",
      "average_pooling2d_11\n",
      "conv2d_115\n",
      "conv2d_117\n",
      "conv2d_120\n",
      "conv2d_121\n",
      "batch_normalization_113\n",
      "batch_normalization_115\n",
      "batch_normalization_118\n",
      "batch_normalization_119\n",
      "activation_113\n",
      "activation_115\n",
      "activation_118\n",
      "activation_119\n",
      "mixed2\n",
      "conv2d_123\n",
      "batch_normalization_121\n",
      "activation_121\n",
      "conv2d_124\n",
      "batch_normalization_122\n",
      "activation_122\n",
      "conv2d_122\n",
      "conv2d_125\n",
      "batch_normalization_120\n",
      "batch_normalization_123\n",
      "activation_120\n",
      "activation_123\n",
      "max_pooling2d_6\n",
      "mixed3\n",
      "conv2d_130\n",
      "batch_normalization_128\n",
      "activation_128\n",
      "conv2d_131\n",
      "batch_normalization_129\n",
      "activation_129\n",
      "conv2d_127\n",
      "conv2d_132\n",
      "batch_normalization_125\n",
      "batch_normalization_130\n",
      "activation_125\n",
      "activation_130\n",
      "conv2d_128\n",
      "conv2d_133\n",
      "batch_normalization_126\n",
      "batch_normalization_131\n",
      "activation_126\n",
      "activation_131\n",
      "average_pooling2d_12\n",
      "conv2d_126\n",
      "conv2d_129\n",
      "conv2d_134\n",
      "conv2d_135\n",
      "batch_normalization_124\n",
      "batch_normalization_127\n",
      "batch_normalization_132\n",
      "batch_normalization_133\n",
      "activation_124\n",
      "activation_127\n",
      "activation_132\n",
      "activation_133\n",
      "mixed4\n",
      "conv2d_140\n",
      "batch_normalization_138\n",
      "activation_138\n",
      "conv2d_141\n",
      "batch_normalization_139\n",
      "activation_139\n",
      "conv2d_137\n",
      "conv2d_142\n",
      "batch_normalization_135\n",
      "batch_normalization_140\n",
      "activation_135\n",
      "activation_140\n",
      "conv2d_138\n",
      "conv2d_143\n",
      "batch_normalization_136\n",
      "batch_normalization_141\n",
      "activation_136\n",
      "activation_141\n",
      "average_pooling2d_13\n",
      "conv2d_136\n",
      "conv2d_139\n",
      "conv2d_144\n",
      "conv2d_145\n",
      "batch_normalization_134\n",
      "batch_normalization_137\n",
      "batch_normalization_142\n",
      "batch_normalization_143\n",
      "activation_134\n",
      "activation_137\n",
      "activation_142\n",
      "activation_143\n",
      "mixed5\n",
      "conv2d_150\n",
      "batch_normalization_148\n",
      "activation_148\n",
      "conv2d_151\n",
      "batch_normalization_149\n",
      "activation_149\n",
      "conv2d_147\n",
      "conv2d_152\n",
      "batch_normalization_145\n",
      "batch_normalization_150\n",
      "activation_145\n",
      "activation_150\n",
      "conv2d_148\n",
      "conv2d_153\n",
      "batch_normalization_146\n",
      "batch_normalization_151\n",
      "activation_146\n",
      "activation_151\n",
      "average_pooling2d_14\n",
      "conv2d_146\n",
      "conv2d_149\n",
      "conv2d_154\n",
      "conv2d_155\n",
      "batch_normalization_144\n",
      "batch_normalization_147\n",
      "batch_normalization_152\n",
      "batch_normalization_153\n",
      "activation_144\n",
      "activation_147\n",
      "activation_152\n",
      "activation_153\n",
      "mixed6\n",
      "conv2d_160\n",
      "batch_normalization_158\n",
      "activation_158\n",
      "conv2d_161\n",
      "batch_normalization_159\n",
      "activation_159\n",
      "conv2d_157\n",
      "conv2d_162\n",
      "batch_normalization_155\n",
      "batch_normalization_160\n",
      "activation_155\n",
      "activation_160\n",
      "conv2d_158\n",
      "conv2d_163\n",
      "batch_normalization_156\n",
      "batch_normalization_161\n",
      "activation_156\n",
      "activation_161\n",
      "average_pooling2d_15\n",
      "conv2d_156\n",
      "conv2d_159\n",
      "conv2d_164\n",
      "conv2d_165\n",
      "batch_normalization_154\n",
      "batch_normalization_157\n",
      "batch_normalization_162\n",
      "batch_normalization_163\n",
      "activation_154\n",
      "activation_157\n",
      "activation_162\n",
      "activation_163\n",
      "mixed7\n",
      "conv2d_168\n",
      "batch_normalization_166\n",
      "activation_166\n",
      "conv2d_169\n",
      "batch_normalization_167\n",
      "activation_167\n",
      "conv2d_166\n",
      "conv2d_170\n",
      "batch_normalization_164\n",
      "batch_normalization_168\n",
      "activation_164\n",
      "activation_168\n",
      "conv2d_167\n",
      "conv2d_171\n",
      "batch_normalization_165\n",
      "batch_normalization_169\n",
      "activation_165\n",
      "activation_169\n",
      "max_pooling2d_7\n",
      "mixed8\n",
      "conv2d_176\n",
      "batch_normalization_174\n",
      "activation_174\n",
      "conv2d_173\n",
      "conv2d_177\n",
      "batch_normalization_171\n",
      "batch_normalization_175\n",
      "activation_171\n",
      "activation_175\n",
      "conv2d_174\n",
      "conv2d_175\n",
      "conv2d_178\n",
      "conv2d_179\n",
      "average_pooling2d_16\n",
      "conv2d_172\n",
      "batch_normalization_172\n",
      "batch_normalization_173\n",
      "batch_normalization_176\n",
      "batch_normalization_177\n",
      "conv2d_180\n",
      "batch_normalization_170\n",
      "activation_172\n",
      "activation_173\n",
      "activation_176\n",
      "activation_177\n",
      "batch_normalization_178\n",
      "activation_170\n",
      "mixed9_0\n",
      "concatenate_2\n",
      "activation_178\n",
      "mixed9\n",
      "conv2d_185\n",
      "batch_normalization_183\n",
      "activation_183\n",
      "conv2d_182\n",
      "conv2d_186\n",
      "batch_normalization_180\n",
      "batch_normalization_184\n",
      "activation_180\n",
      "activation_184\n",
      "conv2d_183\n",
      "conv2d_184\n",
      "conv2d_187\n",
      "conv2d_188\n",
      "average_pooling2d_17\n",
      "conv2d_181\n",
      "batch_normalization_181\n",
      "batch_normalization_182\n",
      "batch_normalization_185\n",
      "batch_normalization_186\n",
      "conv2d_189\n",
      "batch_normalization_179\n",
      "activation_181\n",
      "activation_182\n",
      "activation_185\n",
      "activation_186\n",
      "batch_normalization_187\n",
      "activation_179\n",
      "mixed9_1\n",
      "concatenate_3\n",
      "activation_187\n",
      "mixed10\n"
     ]
    }
   ],
   "source": [
    "for layer in keras_model.layers:\n",
    "    print(layer.name)\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for layer in keras_model.layers[1].layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InceptionV3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_190 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InceptionV3 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_191 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m3,591\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,269,884</span> (92.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,269,884\u001b[0m (92.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,201,229</span> (8.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,201,229\u001b[0m (8.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,867,424</span> (75.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,867,424\u001b[0m (75.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,201,231</span> (8.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,201,231\u001b[0m (8.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradcam_heatmap(keras_model, img_array, layer_name):\n",
    "    #input_shape = (256, 256, 3)  # Ajustez selon votre modèle\n",
    "    input_shape = img_array.shape\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    outputs = keras_model(inputs)\n",
    "    keras_model2 = Model(inputs=inputs, outputs=outputs)\n",
    "    for layer in keras_model.layers:\n",
    "        print(layer.name)\n",
    "    grad_model = Model([keras_model2.input], [keras_model.get_layer(layer_name).output, keras_model2.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, tf.argmax(predictions[0])]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "def apply_gradcam(image_path, keras_model, layer_name):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128)) # Ajustez selon votre modèle\n",
    "    img_array = np.expand_dims(img, axis=-1) # Ajustez selon votre modèle, si besoin de (x,x,3) : np.expand_dims(np.expand_dims(img, axis=-1), axis=0)\n",
    "    print(img_array.shape)\n",
    "\n",
    "    heatmap = get_gradcam_heatmap(keras_model, img_array, layer_name)\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    superimposed_img = heatmap * 0.4 + cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    cv2.imwrite('gradcam_image.jpg', superimposed_img)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 1)\n",
      "conv2d_190\n",
      "InceptionV3\n",
      "conv2d_191\n",
      "flatten_1\n",
      "dense_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_682']\n",
      "Received: inputs=Tensor(shape=(128, 128, 1))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"InceptionV3\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(128, 128, 1, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(128, 128, 1, 1), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from PIL import Image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#img = Image.open(\"./image_0007.jpg\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#img_resized = img.resize((128, 128))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mapply_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./image_0007.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv2d_191\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m, in \u001b[0;36mapply_gradcam\u001b[0;34m(image_path, keras_model, layer_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Ajustez selon votre modèle, si besoin de (x,x,3) : np.expand_dims(np.expand_dims(img, axis=-1), axis=0)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 26\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mget_gradcam_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(heatmap, (img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     29\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m heatmap)\n",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m, in \u001b[0;36mget_gradcam_heatmap\u001b[0;34m(keras_model, img_array, layer_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m Model([keras_model2\u001b[38;5;241m.\u001b[39minput], [keras_model\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\u001b[38;5;241m.\u001b[39moutput, keras_model2\u001b[38;5;241m.\u001b[39moutput])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 11\u001b[0m     conv_outputs, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m predictions[:, tf\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m     13\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, conv_outputs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"InceptionV3\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(128, 128, 1, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(128, 128, 1, 1), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "#from PIL import Image\n",
    "#img = Image.open(\"./image_0007.jpg\")\n",
    "#img_resized = img.resize((128, 128))\n",
    "\n",
    "\n",
    "apply_gradcam(\"./image_0007.jpg\", keras_model, \"conv2d_191\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
