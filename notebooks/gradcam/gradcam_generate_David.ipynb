{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m297.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 09:19:00.022996: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-31 09:19:00.054230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738315140.081710   23121 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738315140.090065   23121 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 09:19:00.116245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from fastapi import APIRouter, File, UploadFile\n",
    "from PIL import Image\n",
    "from fastapi.responses import FileResponse\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import io\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c12881cf7c490fb149b92a64249c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.models.sequential.Sequential'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 18 variables whereas the saved optimizer has 33 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "mlops_server_uri = 'https://david-rem-jedha-final-project-mlops.hf.space'\n",
    "#model_path = 'models:/lung_7_classes/2'\n",
    "model_path = \"runs:/73f7af9ab4be4dd1be44b4653bb2bf06/model\"\n",
    "\n",
    "mlflow.set_tracking_uri(mlops_server_uri)\n",
    "keras_model = mlflow.keras.load_model(model_path)\n",
    "\n",
    "# Vérifier si le modèle est bien chargé\n",
    "print(type(keras_model))  # Doit être <class 'keras.engine.functional.Functional'> ou <class 'tensorflow.keras.Model'>\n",
    "\n",
    "# Tester une entrée factice\n",
    "#dummy_input = np.zeros((1, 256, 256, 3))  # Ajustez la taille si nécessaire\n",
    "#keras_model(dummy_input)\n",
    "#output = keras_model.predict(dummy_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pyfunc_model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_190\n",
      "InceptionV3\n",
      "conv2d_191\n",
      "flatten_1\n",
      "dense_1\n",
      "\n",
      "\n",
      "input_layer_2\n",
      "conv2d_96\n",
      "batch_normalization_94\n",
      "activation_94\n",
      "conv2d_97\n",
      "batch_normalization_95\n",
      "activation_95\n",
      "conv2d_98\n",
      "batch_normalization_96\n",
      "activation_96\n",
      "max_pooling2d_4\n",
      "conv2d_99\n",
      "batch_normalization_97\n",
      "activation_97\n",
      "conv2d_100\n",
      "batch_normalization_98\n",
      "activation_98\n",
      "max_pooling2d_5\n",
      "conv2d_104\n",
      "batch_normalization_102\n",
      "activation_102\n",
      "conv2d_102\n",
      "conv2d_105\n",
      "batch_normalization_100\n",
      "batch_normalization_103\n",
      "activation_100\n",
      "activation_103\n",
      "average_pooling2d_9\n",
      "conv2d_101\n",
      "conv2d_103\n",
      "conv2d_106\n",
      "conv2d_107\n",
      "batch_normalization_99\n",
      "batch_normalization_101\n",
      "batch_normalization_104\n",
      "batch_normalization_105\n",
      "activation_99\n",
      "activation_101\n",
      "activation_104\n",
      "activation_105\n",
      "mixed0\n",
      "conv2d_111\n",
      "batch_normalization_109\n",
      "activation_109\n",
      "conv2d_109\n",
      "conv2d_112\n",
      "batch_normalization_107\n",
      "batch_normalization_110\n",
      "activation_107\n",
      "activation_110\n",
      "average_pooling2d_10\n",
      "conv2d_108\n",
      "conv2d_110\n",
      "conv2d_113\n",
      "conv2d_114\n",
      "batch_normalization_106\n",
      "batch_normalization_108\n",
      "batch_normalization_111\n",
      "batch_normalization_112\n",
      "activation_106\n",
      "activation_108\n",
      "activation_111\n",
      "activation_112\n",
      "mixed1\n",
      "conv2d_118\n",
      "batch_normalization_116\n",
      "activation_116\n",
      "conv2d_116\n",
      "conv2d_119\n",
      "batch_normalization_114\n",
      "batch_normalization_117\n",
      "activation_114\n",
      "activation_117\n",
      "average_pooling2d_11\n",
      "conv2d_115\n",
      "conv2d_117\n",
      "conv2d_120\n",
      "conv2d_121\n",
      "batch_normalization_113\n",
      "batch_normalization_115\n",
      "batch_normalization_118\n",
      "batch_normalization_119\n",
      "activation_113\n",
      "activation_115\n",
      "activation_118\n",
      "activation_119\n",
      "mixed2\n",
      "conv2d_123\n",
      "batch_normalization_121\n",
      "activation_121\n",
      "conv2d_124\n",
      "batch_normalization_122\n",
      "activation_122\n",
      "conv2d_122\n",
      "conv2d_125\n",
      "batch_normalization_120\n",
      "batch_normalization_123\n",
      "activation_120\n",
      "activation_123\n",
      "max_pooling2d_6\n",
      "mixed3\n",
      "conv2d_130\n",
      "batch_normalization_128\n",
      "activation_128\n",
      "conv2d_131\n",
      "batch_normalization_129\n",
      "activation_129\n",
      "conv2d_127\n",
      "conv2d_132\n",
      "batch_normalization_125\n",
      "batch_normalization_130\n",
      "activation_125\n",
      "activation_130\n",
      "conv2d_128\n",
      "conv2d_133\n",
      "batch_normalization_126\n",
      "batch_normalization_131\n",
      "activation_126\n",
      "activation_131\n",
      "average_pooling2d_12\n",
      "conv2d_126\n",
      "conv2d_129\n",
      "conv2d_134\n",
      "conv2d_135\n",
      "batch_normalization_124\n",
      "batch_normalization_127\n",
      "batch_normalization_132\n",
      "batch_normalization_133\n",
      "activation_124\n",
      "activation_127\n",
      "activation_132\n",
      "activation_133\n",
      "mixed4\n",
      "conv2d_140\n",
      "batch_normalization_138\n",
      "activation_138\n",
      "conv2d_141\n",
      "batch_normalization_139\n",
      "activation_139\n",
      "conv2d_137\n",
      "conv2d_142\n",
      "batch_normalization_135\n",
      "batch_normalization_140\n",
      "activation_135\n",
      "activation_140\n",
      "conv2d_138\n",
      "conv2d_143\n",
      "batch_normalization_136\n",
      "batch_normalization_141\n",
      "activation_136\n",
      "activation_141\n",
      "average_pooling2d_13\n",
      "conv2d_136\n",
      "conv2d_139\n",
      "conv2d_144\n",
      "conv2d_145\n",
      "batch_normalization_134\n",
      "batch_normalization_137\n",
      "batch_normalization_142\n",
      "batch_normalization_143\n",
      "activation_134\n",
      "activation_137\n",
      "activation_142\n",
      "activation_143\n",
      "mixed5\n",
      "conv2d_150\n",
      "batch_normalization_148\n",
      "activation_148\n",
      "conv2d_151\n",
      "batch_normalization_149\n",
      "activation_149\n",
      "conv2d_147\n",
      "conv2d_152\n",
      "batch_normalization_145\n",
      "batch_normalization_150\n",
      "activation_145\n",
      "activation_150\n",
      "conv2d_148\n",
      "conv2d_153\n",
      "batch_normalization_146\n",
      "batch_normalization_151\n",
      "activation_146\n",
      "activation_151\n",
      "average_pooling2d_14\n",
      "conv2d_146\n",
      "conv2d_149\n",
      "conv2d_154\n",
      "conv2d_155\n",
      "batch_normalization_144\n",
      "batch_normalization_147\n",
      "batch_normalization_152\n",
      "batch_normalization_153\n",
      "activation_144\n",
      "activation_147\n",
      "activation_152\n",
      "activation_153\n",
      "mixed6\n",
      "conv2d_160\n",
      "batch_normalization_158\n",
      "activation_158\n",
      "conv2d_161\n",
      "batch_normalization_159\n",
      "activation_159\n",
      "conv2d_157\n",
      "conv2d_162\n",
      "batch_normalization_155\n",
      "batch_normalization_160\n",
      "activation_155\n",
      "activation_160\n",
      "conv2d_158\n",
      "conv2d_163\n",
      "batch_normalization_156\n",
      "batch_normalization_161\n",
      "activation_156\n",
      "activation_161\n",
      "average_pooling2d_15\n",
      "conv2d_156\n",
      "conv2d_159\n",
      "conv2d_164\n",
      "conv2d_165\n",
      "batch_normalization_154\n",
      "batch_normalization_157\n",
      "batch_normalization_162\n",
      "batch_normalization_163\n",
      "activation_154\n",
      "activation_157\n",
      "activation_162\n",
      "activation_163\n",
      "mixed7\n",
      "conv2d_168\n",
      "batch_normalization_166\n",
      "activation_166\n",
      "conv2d_169\n",
      "batch_normalization_167\n",
      "activation_167\n",
      "conv2d_166\n",
      "conv2d_170\n",
      "batch_normalization_164\n",
      "batch_normalization_168\n",
      "activation_164\n",
      "activation_168\n",
      "conv2d_167\n",
      "conv2d_171\n",
      "batch_normalization_165\n",
      "batch_normalization_169\n",
      "activation_165\n",
      "activation_169\n",
      "max_pooling2d_7\n",
      "mixed8\n",
      "conv2d_176\n",
      "batch_normalization_174\n",
      "activation_174\n",
      "conv2d_173\n",
      "conv2d_177\n",
      "batch_normalization_171\n",
      "batch_normalization_175\n",
      "activation_171\n",
      "activation_175\n",
      "conv2d_174\n",
      "conv2d_175\n",
      "conv2d_178\n",
      "conv2d_179\n",
      "average_pooling2d_16\n",
      "conv2d_172\n",
      "batch_normalization_172\n",
      "batch_normalization_173\n",
      "batch_normalization_176\n",
      "batch_normalization_177\n",
      "conv2d_180\n",
      "batch_normalization_170\n",
      "activation_172\n",
      "activation_173\n",
      "activation_176\n",
      "activation_177\n",
      "batch_normalization_178\n",
      "activation_170\n",
      "mixed9_0\n",
      "concatenate_2\n",
      "activation_178\n",
      "mixed9\n",
      "conv2d_185\n",
      "batch_normalization_183\n",
      "activation_183\n",
      "conv2d_182\n",
      "conv2d_186\n",
      "batch_normalization_180\n",
      "batch_normalization_184\n",
      "activation_180\n",
      "activation_184\n",
      "conv2d_183\n",
      "conv2d_184\n",
      "conv2d_187\n",
      "conv2d_188\n",
      "average_pooling2d_17\n",
      "conv2d_181\n",
      "batch_normalization_181\n",
      "batch_normalization_182\n",
      "batch_normalization_185\n",
      "batch_normalization_186\n",
      "conv2d_189\n",
      "batch_normalization_179\n",
      "activation_181\n",
      "activation_182\n",
      "activation_185\n",
      "activation_186\n",
      "batch_normalization_187\n",
      "activation_179\n",
      "mixed9_1\n",
      "concatenate_3\n",
      "activation_187\n",
      "mixed10\n"
     ]
    }
   ],
   "source": [
    "for layer in keras_model.layers:\n",
    "    print(layer.name)\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for layer in keras_model.layers[1].layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InceptionV3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_190 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InceptionV3 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_191 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m3,591\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,269,884</span> (92.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,269,884\u001b[0m (92.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,201,229</span> (8.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,201,229\u001b[0m (8.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,867,424</span> (75.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,867,424\u001b[0m (75.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,201,231</span> (8.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,201,231\u001b[0m (8.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradcam_heatmap(keras_model, img_array, layer_name):\n",
    "    #input_shape = (256, 256, 3)  # Ajustez selon votre modèle\n",
    "    input_shape = img_array.shape\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    outputs = keras_model(inputs)\n",
    "    keras_model2 = Model(inputs=inputs, outputs=outputs)\n",
    "    for layer in keras_model.layers:\n",
    "        print(layer.name)\n",
    "    grad_model = Model([keras_model2.input], [keras_model.get_layer(layer_name).output, keras_model2.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, tf.argmax(predictions[0])]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "def apply_gradcam(image_path, keras_model, layer_name):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128)) # Ajustez selon votre modèle\n",
    "    print(img.shape)\n",
    "    img_array = np.expand_dims(img, axis=-1) # Ajustez selon votre modèle, si besoin de (x,x,3) : np.expand_dims(np.expand_dims(img, axis=-1), axis=0)\n",
    "    print(img_array.shape)\n",
    "\n",
    "    heatmap = get_gradcam_heatmap(keras_model, img_array, layer_name)\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    superimposed_img = heatmap * 0.4 + cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    cv2.imwrite('gradcam_image.jpg', superimposed_img)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "(128, 128, 1)\n",
      "conv2d_190\n",
      "InceptionV3\n",
      "conv2d_191\n",
      "flatten_1\n",
      "dense_1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The name \"input_layer_3\" is used 2 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from PIL import Image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#img = Image.open(\"./image_0007.jpg\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#img_resized = img.resize((128, 128))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mapply_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./image_0007.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv2d_191\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#apply_gradcam(\"./image_0007.jpg\", keras_model, \"mixed10\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m, in \u001b[0;36mapply_gradcam\u001b[0;34m(image_path, keras_model, layer_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Ajustez selon votre modèle, si besoin de (x,x,3) : np.expand_dims(np.expand_dims(img, axis=-1), axis=0)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 27\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mget_gradcam_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(heatmap, (img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     30\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m heatmap)\n",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mget_gradcam_heatmap\u001b[0;34m(keras_model, img_array, layer_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m keras_model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m----> 9\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeras_model2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras_model2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     11\u001b[0m     conv_outputs, predictions \u001b[38;5;241m=\u001b[39m grad_model(img_array)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/ops/function.py:329\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"input_layer_3\" is used 2 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "#from PIL import Image\n",
    "#img = Image.open(\"./image_0007.jpg\")\n",
    "#img_resized = img.resize((128, 128))\n",
    "\n",
    "\n",
    "apply_gradcam(\"./image_0007.jpg\", keras_model, \"conv2d_191\")\n",
    "#apply_gradcam(\"./image_0007.jpg\", keras_model, \"mixed10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
